{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "xgboost.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzafarooq/time_series/blob/master/xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Pmxv2ioyCRw"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "b-2ShX25yNWf",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# Time series forecasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPOyXTATKc_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ray tune dependencies\n",
        "!pip install -q ray[debug]\n",
        "!pip install ray[tune]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVb7L94KKtzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ray tune imports\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7rZnJaGTWQw0",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIFtGuUqTvBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import imageio\n",
        "import os\n",
        "from statsmodels.graphics.tsaplots import plot_acf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TokBlnUhWFw9"
      },
      "source": [
        "## Iowa Dataset\n",
        "This tutorial uses a <a href=\"https://console.cloud.google.com/marketplace/details/iowa-department-of-commerce/iowa-liquor-sales\" class=\"external\">Iowa Liquor Retails Sales</a>.\n",
        "\n",
        "This dataset contains every wholesale purchase of liquor in the State of Iowa by retailers for sale to individuals since January 1, 2012. The State of Iowa controls the wholesale distribution of liquor intended for retail sale, which means this dataset offers a complete view of retail liquor sales in the entire state. The dataset contains every wholesale order of liquor by all grocery stores, liquor stores, convenience stores, etc., with details about the store and location, the exact liquor brand and size, and the number of bottles ordered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SeTJb51SKs_W",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cLh05lDpJ4wj",
        "colab": {}
      },
      "source": [
        "# Save output in a variable `df`\n",
        "\n",
        "%%bigquery --project bold-sorter-281506 df\n",
        "SELECT \n",
        "  * \n",
        "FROM `bigquery-public-data.iowa_liquor_sales.sales`\n",
        "where store_number  = '2633'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VdbOWXiTWM2T"
      },
      "source": [
        "Let's take a glance at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ojHE-iCCWIhz",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsbUCqS7p69J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe()\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbLFfG7tqNA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_single_item_aggregate =df[['date','sale_dollars']]\n",
        "df_single_item_aggregate['date'] = pd.to_datetime(df_single_item_aggregate['date'])\n",
        "#print(type(date_object))\n",
        "#print(date_object) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1CEddh4qw_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_single_item_aggregate = df_single_item_aggregate.groupby(['date']).sum().rename_axis('date')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47LioiQWsr-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df_single_item_aggregate['flag'] = pd.Series(np.where(df_single_item_aggregate.index >= np.datetime64('2020-01-25'), 1, 0),index=df_single_item_aggregate.index)\n",
        "df_single_item_aggregate\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoOEZZkhT8XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(data, split_date):\n",
        "    return data[data.index <= split_date].copy(), \\\n",
        "           data[data.index >  split_date].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOsMKEuH68p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = split_data(df_single_item_aggregate, '2020-02-01')\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('close')\n",
        "plt.plot(train.index,train)\n",
        "plt.plot(test.index,test)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VCzq15Qov5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY9QMcdxkqki",
        "colab_type": "text"
      },
      "source": [
        "# xgboost Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBZzpZXtiXJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_features(df):\n",
        "    \"\"\"\n",
        "    Creates time series features from datetime index\n",
        "    \"\"\"\n",
        "    df['date'] = df.index\n",
        "    df['dayofweek'] = df['date'].dt.dayofweek\n",
        "    df['quarter'] = df['date'].dt.quarter\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['dayofyear'] = df['date'].dt.dayofyear\n",
        "    df['dayofmonth'] = df['date'].dt.day\n",
        "    df['weekofyear'] = df['date'].dt.weekofyear\n",
        "    df['flag'] = pd.Series(np.where(df['date'] >= np.datetime64('2020-01-25'), 1, 0), index=df.index)\n",
        "    \n",
        "    X = df[['dayofweek','quarter','month','year',\n",
        "           'dayofyear','dayofmonth','weekofyear','flag']]\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp-SoRNzie3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = create_features(train), train['sale_dollars']\n",
        "X_test, y_test   = create_features(test), test['sale_dollars']\n",
        "\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bUeykQ1ijJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.head()\n",
        "\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DWuQirBKKWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df['flag'] = pd.Series(np.where(df['date'] >= np.datetime64('2020-01-25'), 1, 0), index=df.index)\n",
        "X_train.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qdi09dLilxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg = xgb.XGBRegressor(n_estimators=1000)\n",
        "reg.fit(X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "        early_stopping_rounds=500, #stop if 50 consequent rounds without decrease of error\n",
        "        verbose=False) # Change verbose to True if you want to see it train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuaM8Ip3i7VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb.plot_importance(reg, height=0.9)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM-oLoWnjYMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_performance(base_data, date_from, date_to, title=None):\n",
        "    plt.figure(figsize=(15,3))\n",
        "    if title == None:\n",
        "        plt.title('From {0} To {1}'.format(date_from, date_to))\n",
        "    else:\n",
        "        plt.title(title)\n",
        "    plt.xlabel('time')\n",
        "    plt.ylabel('close')\n",
        "    plt.plot(df_single_item_aggregate.index,df_single_item_aggregate, label='data')\n",
        "    plt.plot(X_test.index,X_test_pred, label='prediction')\n",
        "    plt.legend()\n",
        "    plt.xlim(left=date_from, right=date_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lka4QPrjez1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb.plot_importance(reg, height=0.9)\n",
        "X_test_pred = reg.predict(X_test)\n",
        "    \n",
        "plot_performance(df_single_item_aggregate, df_single_item_aggregate.index[0].date(), df_single_item_aggregate.index[-1].date(),\n",
        "                 'Original and Predicted Data')\n",
        "\n",
        "plot_performance(y_test, y_test.index[0].date(), y_test.index[-1].date(),\n",
        "                 'Test and Predicted Data')\n",
        "\n",
        "#plot_performance(y_test, '2019-7-01', '2019-8-01', 'Snapshot')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJJcSEyYjjr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "mean_absolute_percentage_error(y_test,X_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLNawTH-_0tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_smape(y_hat, y):\n",
        "        return 100/len(y) * np.sum(2 * np.abs(y_hat - y) / (np.abs(y) + np.abs(y_hat)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrlsJiFM_2Lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calc_smape(y_test,X_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXBtq1oHkVok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error_by_week = []\n",
        "random_weeks = X_test[['year', 'weekofyear']].sample(10)\n",
        "for week in random_weeks.iterrows():\n",
        "    index = (X_test.year == week[1].year) & \\\n",
        "            (X_test.weekofyear == week[1].weekofyear)\n",
        "    error_by_week.append(mean_absolute_percentage_error(y_test[index], X_test_pred[index]))\n",
        "pd.Series(error_by_week, index=random_weeks.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17ZOQ4w_zF_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR-aPTCMqT-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def XGBCallback(env):\n",
        "    # After every training iteration, report loss to Tune\n",
        "    tune.report(**dict(env.evaluation_result_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phMUw2qePSLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train_numpy = X_train.to_numpy()\n",
        "# X_test_numpy = X_test.to_numpy()\n",
        "# y_train_numpy = np.reshape(y_train.to_numpy(), (y_train.shape[0], 1))\n",
        "# y_test_numpy = np.reshape(y_test.to_numpy(), (y_test.shape[0], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prii4u4bWeY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train_numpy[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Mrj1awXLhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amEF9pzMyhyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_forecaster_tune(config):\n",
        "    X_train_numpy = X_train.to_numpy()\n",
        "    X_test_numpy = X_test.to_numpy()\n",
        "    y_train_numpy = np.reshape(y_train.to_numpy(), (y_train.shape[0], 1))\n",
        "    y_test_numpy = np.reshape(y_test.to_numpy(), (y_test.shape[0], 1))\n",
        "\n",
        "    train_set = xgb.DMatrix(X_train_numpy, label=y_train_numpy)\n",
        "    test_set = xgb.DMatrix(X_test_numpy, label=y_test_numpy)\n",
        "\n",
        "    # Train the classifier\n",
        "    bst = xgb.train(\n",
        "        config,\n",
        "        train_set,\n",
        "        evals=[(test_set, \"eval\")],\n",
        "        verbose_eval=False,\n",
        "        callbacks=[XGBCallback])\n",
        "    # Predict labels for the test set\n",
        "    preds = bst.predict(test_set)\n",
        "    # pred_labels = np.rint(preds)\n",
        "    # Return prediction accuracy\n",
        "    # accuracy = sklearn.metrics.accuracy_score(test_y, pred_labels)\n",
        "    # tune.report(mean_accuracy=accuracy, done=True)\n",
        "    score = calc_smape(y_test_numpy, preds)\n",
        "    tune.report(mean_accuracy=score, done=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFZ4UFyRcPn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {\n",
        "  \"objective\": \"reg:squarederror\",\n",
        "  \"max_depth\": tune.randint(1, 9),\n",
        "  \"min_child_weight\": tune.choice([1, 2, 3]),\n",
        "  \"subsample\": tune.uniform(0.5, 1.0),\n",
        "  \"eta\": tune.loguniform(1e-4, 1e-1),\n",
        "  \"eval_metric\": [\"ams@0\", \"logloss\"],\n",
        "  \"n_estimators\": 10000\n",
        "\n",
        "}\n",
        "\n",
        "# The ASHAScheduler stops bad performing configurations early\n",
        "scheduler = ASHAScheduler(\n",
        "  metric=\"eval-logloss\",  # The `eval` prefix is defined in xgb.train\n",
        "  mode=\"max\",  # Retain configurations with a low logloss\n",
        "  max_t=11,  # 10 training iterations + 1 final evaluation\n",
        "  grace_period=1,  # Number of minimum iterations for each trial\n",
        "  reduction_factor=2)  # How aggressively to stop trials\n",
        "analysis = tune.run(\n",
        "  train_forecaster_tune,  # your training function\n",
        "  resources_per_trial={\"gpu\": 1},  # You can add \"gpu\": 0.1 here\n",
        "  config=config,\n",
        "  num_samples=10,  # number of parameter configurations to try\n",
        "  scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WXZ1nwLzoTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "best_config = analysis.get_best_logdir('mean_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJPdigG2fE85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str(best_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xNGJBRS0RQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJDqkT66YduX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analysis.dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg9OxEnsYx-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}